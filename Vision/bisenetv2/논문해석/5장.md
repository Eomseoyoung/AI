> ### 5. 실험 결과 (Experimental Results)
> 
> 본 절에서는 먼저 사용한 데이터셋과 구현 세부 사항을 소개한다.
> 이후 Cityscapes 검증 세트에서 제안한 각 구성 요소의 효과를 분석하는 어블레이션 실험을 수행하고,
> 마지막으로 여러 벤치마크에서 다른 알고리즘들과의 정확도 및 속도 비교 결과를 제시한다.
>

> ### 5.1 데이터셋 (Datasets)
>
> #### Cityscapes
> 
> Cityscapes 데이터셋은 차량 시점에서 촬영된 도시 도로 장면의 의미적 이해를 목표로 한다.
> 이 데이터셋은 다음과 같이 분할된다.
> 
> * 학습(train): 2,975장, 검증(validation): 500장, 테스트(test): 1,525장
>   
> 총 30개의 클래스가 주석으로 제공되며, 이 중 19개 클래스가 의미 분할 평가에 사용된다.
> 입력 해상도가 2048×1024로 매우 크기 때문에, 실시간 의미 분할 관점에서 특히 도전적인 데이터셋이다.
>
> #### CamVid
> 
> CamVid(Cambridge-driving Labeled Video Database)는 주행 차량 시점에서 촬영된 도로 장면 데이터셋이다.
> 
> * 전체 이미지 수 : 701장
> * 해상도 : 960x720
>   
> 기존 연구 관례에 따라 다음과 같이 분할한다.
> * 학습: 367장, 검증: 101장, 테스트: 233장
>   
> 총 32개 클래스 중 11개 클래스만을 사용하며, 나머지 픽셀은 무시된다.
>
> #### COCO-Stuff
> 
> COCO-Stuff는 COCO 데이터셋에 stuff 클래스에 대한 밀집 주석(dense annotation)을 추가한 데이터셋이다.
> 
> * 학습 : 9,000장, 테스트 : 1,000장
> 총 182개 클래스(thing 91 + stuff 91)를 포함하며, 실시간 의미 분할 관점에서 매우 복잡한 데이터셋이다.

> ### 5.2 학습 설정 (Training)
> 
> 모든 모델은 scratch부터 학습하며, 가중치 초기화는 Kaiming Normal 방식을 사용한다.
>
> * 최적화 방법 :SGD
> * Momentum : 0.9
> * batch size : 16
>
> 가중치 감쇠(weight decay):
> * Cityscapes, CamVid : 0.0005
> * COCO-Stuff : 0.0001
>
> 가중치 감쇠는 합성곱 계층 파라미터에만 적용한다.
> 
> #### 학습률 스케줄
> 
> * 초기 학습률: 5×10⁻²
> * Poly learning rate 정책 사용
>   
>   <img width="207" height="85" alt="image" src="https://github.com/user-attachments/assets/e9499c9a-a7d9-4336-be41-adf04fdd5795" />
>
> 학습 반복 수:
>
> * Cityscapes: 150K iterations
> * CamVid: 10K iterations
> * COCO-Stuff: 20K iterations
>   
> #### 데이터 증강(Augmentation)
> 
> * 수평 뒤집기
> * 랜덤 스케일링
> * 랜덤 크롭
> 
> 스케일 비율:
> {0.75, 1, 1.25, 1.5, 1.75, 2.0}
>
> 크롭 해상도:
>
> * Cityscapes: 2048×1024
> * CamVid: 960×720
> * COCO-Stuff: 640×640
>   
> Cityscapes의 경우, 증강 후 1024×512로 리사이즈하여 학습한다.

> ### 5.3 추론 설정 (Inference)
> 
> * 슬라이딩 윈도우, 멀티스케일 테스트 등 시간 소모가 큰 기법은 사용하지 않음
> * 입력(2048×1024)을 먼저 1024×512로 리사이즈하여 추론
> * 출력 결과를 다시 원본 해상도로 복원
>
> 추론 시간 측정 :
> * GPU 1장 사용
> * 5000회 반복 측정하여 오차 제거
> * 리사이즈 시간 포함
>
> 평가지표 :
> * Cityscapes, CamVid: mIoU
> * COCO-Stuff: mIoU + Pixel Accuracy

> ### 5.4 Cityscapes 어블레이션 실험 (Ablation Study)
>
> #### 개별 분기 효과 분석
> 
> Detail Branch 단독:
> * 고수준 의미 정보 부족
>   
> Semantic Branch 단독:
>
> * 저수준 공간 디테일 부족
>   -> 단독 사용 시 성능이 모두 낮음
>
> 그러나 두 분기를 결합하면 서로 보완적 표현을 제공하여 성능이 크게 향상된다.
>
> * Semantic Branch 단독: 64.68% mIoU
> * Detail Branch 단독: 62.35% mIoU
> * 단순 결합 시: 6% 이상 성능 향상
>
> 이는 두 분기의 표현이 상호 보완적임을 보여준다.
>
> #### Aggregation 방식 비교
>
> 비교한 방식 :
> 
> * 단순 합
> * 채널 결합
> * Bilateral Guided Aggregation (제안 방식)
>
> 결과적으로 BGA가 정확도와 효율성 모두에서 가장 우수했다.
>
> ### Semantic Branch 설계 분석
>
> (1) 채널 비율 λ
> λ = 1/16인 경우에도 Detail Branch 단독 대비 6% mIoU 향상을 달성하였다.
> 
> 본 논문에서는 λ = 1/4를 기본값으로 사용한다.
>
> (2) GE Layer 구조
> * 두 개의 3×3 depth-wise convolution은 5×5 depth-wise convolution 대비 FLOPs가 적고 수용 영역은 동일
> * GE Layer는 의미 정보 표현에 효과적임을 입증
>
> (3) 확장 비율 ε (Expansion Ratio)
> ε = 1만 사용해도 4% 이상의 성능 향상이 발생하였다.
> 최적의 정확도–연산량 균형을 위해 ε = 6을 채택한다.
>
> #### Booster 학습 전략
> 
> Semantic Branch 중간에 **보조 분할 헤드(auxiliary head)**를 삽입하여 학습 시 성능을 향상시킨다.
> 
> 이 헤드들은 추론 시 제거되므로 속도에는 영향이 없다.
> Booster 적용 결과:
> * mIoU 약 3% 추가 향상
> * 추론 속도 유지
